# ğŸ¤– RAG System with Gemini Flash 2.0, Milvus & Redis

A comprehensive Retrieval-Augmented Generation (RAG) system featuring **Google Gemini Flash 2.0** LLM, document upload, intelligent caching, and AI-powered question answering with a beautiful **Streamlit interface**.

## ğŸŒŸ Features

- **ğŸ¤– Gemini Flash 2.0**: Latest Google AI model for superior performance
- **ğŸ“ Document Processing**: Support for PDF, TXT, DOCX files
- **ğŸ” Smart Q&A**: Ask questions and get answers with source citations
- **ï¿½ Redis Caching**: Lightning-fast response caching
- **ï¿½ï¸ Milvus Vector DB**: High-performance vector similarity search
- **ğŸ¨ Modern Web UI**: Interactive **Streamlit** interface
- **ğŸ’» CLI Interface**: Command-line tools for advanced users
- **ï¿½ Real-time Analytics**: System statistics and performance monitoring

## ğŸ“‹ Prerequisites

### Required Services

1. **Docker Desktop** 
   - Download from [Docker Desktop](https://www.docker.com/products/docker-desktop/)
   - Make sure Docker is running before starting

2. **Google API Key** (Required)
   - Get your API key from [Google AI Studio](https://ai.google.dev/)
   - The key is needed for Gemini Flash 2.0 access

### System Requirements

- Python 3.8+
- 4GB+ RAM
- 2GB+ disk space
- Docker Desktop

## ğŸš€ Quick Start

### 1. One-Click Setup (Windows)

Simply run the optimized startup script:

```bash
start.bat
```

This script will:
- âœ… Set up Python virtual environment
- âœ… Install all dependencies
- âœ… Start Docker services (Milvus + Redis)
- âœ… Create .env configuration file
- âœ… Launch your chosen interface (Web or CLI)

1. **Clone and Setup**
```bash
# Navigate to project directory
cd e:\lamaindex

# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

2. **Configuration**
```bash
# Copy environment template
copy .env.example .env
```

Edit `.env` file with your Google API key:
```env
# Google Gemini Configuration (Required)
GOOGLE_API_KEY=your_google_api_key_here

# Optional: OpenAI for hybrid mode
OPENAI_API_KEY=your_openai_api_key_here

# Service Configuration (defaults work fine)
MILVUS_HOST=localhost
MILVUS_PORT=19530
REDIS_HOST=localhost
REDIS_PORT=6379
GEMINI_MODEL=gemini-2.0-flash-exp
```bash
docker-compose -f docker-compose-milvus.yml up -d
```

4. **Run the Application**

**Web Interface (Recommended):**
```bash
streamlit run streamlit_app.py
```

**Command Line Interface:**
```bash
python main_gemini.py --interactive
```

**Or simply use the startup script:**
```bash
start.bat  # Windows
```

## ğŸ¯ Usage

### ğŸ“± Web Interface (Streamlit)

1. **Start the app**: Run `start.bat` or `streamlit run streamlit_app.py`
2. **Open browser**: Navigate to `http://localhost:8501`
3. **Choose model**: Select between "Gemini (Full)" or "Hybrid" mode
4. **Upload documents**: Use the sidebar to upload PDF, TXT, or DOCX files
5. **Ask questions**: Type your questions in the chat interface
6. **View sources**: See which documents were used to generate answers

### ğŸ’» Command Line Interface

```bash
# Interactive chat mode
python main_gemini.py --interactive

# Single query
python main_gemini.py --query "What is this document about?"

# Upload a file
python main_gemini.py --upload "path/to/your/document.pdf"

# Show help
python main_gemini.py --help
```

## ğŸ¨ Interface Features

### ğŸ  Main Dashboard
- **Model Selection**: Choose between full Gemini or hybrid mode
- **System Status**: Real-time monitoring of services
- **Quick Stats**: Document count, cache status, and performance metrics

### ï¿½ Document Upload
- **Multi-file Upload**: Drag & drop or select multiple files
- **Real-time Progress**: Visual progress bars during processing
- **Format Support**: PDF, TXT, DOCX with validation
- **Upload Guidelines**: Tips and file limits

### ğŸ’¬ Chat Interface  
- **Conversational AI**: Natural language question answering
- **Chat History**: Persistent conversation memory
- **Source Citations**: Expandable source references
- **Cache Indicators**: Shows when results are cached

### ğŸ” Document Search
- **Semantic Search**: Find similar content using AI
- **Adjustable Results**: Slider for number of results (1-20)  
- **Relevance Scores**: Similarity scores for each result
- **Content Preview**: Truncated text with full metadata

### ğŸ“Š Statistics Dashboard
- **System Metrics**: Document count, cache performance
- **Visual Charts**: Pie charts for cache hit/miss rates  
- **Upload Timeline**: Interactive timeline of document uploads
- **Performance Monitoring**: Memory usage, hit rates

### âš™ï¸ Settings & Management
- **Environment Status**: Check required API keys and services
- **System Configuration**: Current settings display
- **Data Management**: Clear cache or all data options
- **Troubleshooting**: System information and diagnostics

## ğŸš€ Running Different Interfaces

### ğŸ¨ Streamlit UI (Recommended)
```bash
# Windows
run_streamlit.bat

# Linux/Mac  
./run_streamlit.sh

# Manual
streamlit run streamlit_app.py
```
Access at: http://localhost:8501

### ğŸ’» Command Line Interface
```bash
# Interactive mode (great for testing)
python main.py --interactive

# Direct commands
python main.py --upload "documents/sample.pdf"
python main.py --query "What is this document about?"
python main.py --search "artificial intelligence" 
python main.py --stats
```

### ğŸŒ FastAPI Web Interface
```bash
python web_app.py
```
Access at: http://localhost:8000

## ğŸ“– Usage Guide

### 1. Upload Documents

**CLI:**
```bash
# Interactive mode
> upload documents/sample.pdf

# Direct command
python main.py --upload "documents/sample.pdf"
```

**Web Interface:**
1. Open http://localhost:8000
2. Use the "Upload Document" section
3. Select your file and click "Upload & Process"

### 2. Query Documents

**CLI:**
```bash
# Interactive mode
> query What are the main topics in the document?

# Direct command
python main.py --query "What are the main topics?"
```

**Web Interface:**
1. Use the "Ask a Question" section
2. Enter your question and click "Ask Question"
3. View response with source attributions

### 3. Search Similar Content

**CLI:**
```bash
# Interactive mode
> search machine learning concepts

# Direct command
python main.py --search "machine learning"
```

### 4. System Statistics

**CLI:**
```bash
# Interactive mode
> stats

# Direct command
python main.py --stats
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input    â”‚â”€â”€â”€â”€â”‚   RAG System     â”‚â”€â”€â”€â”€â”‚   Response      â”‚
â”‚ (CLI/Web)       â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ File Handler    â”‚    â”‚   Query Engine   â”‚    â”‚ Cache Manager   â”‚
â”‚ - PDF Reader    â”‚    â”‚ - Retriever      â”‚    â”‚ - Redis         â”‚
â”‚ - DOCX Reader   â”‚    â”‚ - Post-processor â”‚    â”‚ - Search Cache  â”‚
â”‚ - Text Splitter â”‚    â”‚ - LLM (OpenAI)   â”‚    â”‚ - Embeddings    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Vector Database  â”‚
                    â”‚ - Milvus         â”‚
                    â”‚ - Embeddings     â”‚
                    â”‚ - Similarity     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration Options

### Document Processing
- `CHUNK_SIZE`: Size of text chunks (default: 1024)
- `CHUNK_OVERLAP`: Overlap between chunks (default: 200)
- `MAX_FILE_SIZE_MB`: Maximum file size (default: 100MB)

### Vector Database
- `MILVUS_HOST`: Milvus server host
- `MILVUS_PORT`: Milvus server port
- `EMBEDDING_DIMENSION`: Vector dimensions (default: 1536 for OpenAI)

### Caching
- `CACHE_TTL_SECONDS`: Cache expiration time (default: 3600s)
- `ENABLE_CACHE`: Enable/disable caching (default: true)

## ğŸš€ API Endpoints (Web Interface)

- `GET /`: Main web interface
- `POST /upload/`: Upload and process documents
- `POST /query/`: Query the RAG system
- `POST /search/`: Search similar documents
- `GET /stats/`: Get system statistics
- `DELETE /clear/`: Clear all data

## ğŸ“Š Monitoring & Statistics

The system provides comprehensive statistics:

- **Document Statistics**: Total documents, chunks, collection info
- **Cache Performance**: Hit rate, memory usage, key counts
- **File Management**: Uploaded files, processing status

## ğŸ” Troubleshooting

### Common Issues

1. **Milvus Connection Error**
   ```bash
   # Check if Milvus is running
   docker ps | grep milvus
   # Or check local installation
   ```

2. **Redis Connection Error**
   ```bash
   # Check if Redis is running
   redis-cli ping
   # Should return "PONG"
   ```

3. **Docker Issues**

   **Docker not found:**
   ```bash
   # Install Docker Desktop first
   # Windows/Mac: https://www.docker.com/products/docker-desktop/
   # Linux: https://docs.docker.com/engine/install/
   ```

   **Services won't start:**
   ```bash
   # Check if ports are in use
   netstat -an | findstr "19530\|6379"  # Windows
   netstat -an | grep "19530\|6379"     # Linux/Mac

   # Free up ports or change configuration
   ```

   **Docker Compose errors:**
   ```bash
   # Update Docker Compose
   docker-compose --version

   # Recreate containers
   docker-compose down -v
   docker-compose up -d
   ```

   **Container health issues:**
   ```bash
   # Check container logs
   docker-compose logs milvus
   docker-compose logs redis

   # Restart specific service
   docker-compose restart milvus
   ```

   **Permission issues (Linux):**
   ```bash
   # Add user to docker group
   sudo usermod -aG docker $USER
   # Logout and login again
   ```

4. **OpenAI API Errors**
   - Verify API key in `.env`
   - Check API quotas and billing
   - Ensure internet connectivity

5. **File Processing Errors**
   - Check file format (PDF, TXT, DOCX only)
   - Verify file size limit
   - Ensure file is not corrupted

### Performance Optimization

1. **Adjust chunk size** for better retrieval
2. **Enable caching** for faster responses
3. **Use SSD storage** for Milvus data
4. **Increase RAM** for better vector operations

## ğŸ”’ Security Notes

- Keep your OpenAI API key secure
- Use authentication for production deployments
- Configure firewall rules for Milvus/Redis
- Regular backup of vector data

## ğŸ“ Project Structure (Optimized)

```
e:\lamaindex\
â”œâ”€â”€ ğŸ“ src/                     # Core application code
â”‚   â”œâ”€â”€ rag_system.py          # Main RAG orchestrator (hybrid mode)
â”‚   â”œâ”€â”€ gemini_rag_system.py   # Full Gemini implementation
â”‚   â”œâ”€â”€ milvus_manager.py      # Milvus vector database manager
â”‚   â”œâ”€â”€ redis_cache.py         # Redis caching layer
â”‚   â”œâ”€â”€ file_handler.py        # Document processing utilities
â”‚   â””â”€â”€ logging_config.py      # Logging configuration
â”œâ”€â”€ ğŸ“ config/                 # Configuration files
â”‚   â””â”€â”€ settings.py           # Application settings
â”œâ”€â”€ ğŸ“ uploads/               # Uploaded documents storage
â”œâ”€â”€ ğŸ“ data/                  # Processed data cache
â”œâ”€â”€ ğŸš€ start.bat              # Optimized one-click startup script
â”œâ”€â”€ ğŸŒ streamlit_app.py       # Streamlit web interface
â”œâ”€â”€ ğŸ’» main_gemini.py         # Command-line interface
â”œâ”€â”€ ğŸ³ docker-compose-milvus.yml # Docker services configuration
â”œâ”€â”€ ğŸ”§ requirements.txt       # Python dependencies
â”œâ”€â”€ âš™ï¸  .env.example          # Environment configuration template
â””â”€â”€ ğŸ“– README.md              # This file
```

### Key Components

- **ğŸ¤– Gemini Integration**: Two modes available - Full Gemini or Hybrid (Gemini LLM + OpenAI embeddings)
- **ğŸ“¦ Single Startup**: One `start.bat` script handles everything
- **ğŸ¯ Clean Architecture**: Separated concerns with modular design
- **ğŸ³ Docker Services**: Only Milvus and Redis, no unnecessary containers

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ†˜ Support

For issues and questions:
1. Check the troubleshooting section
2. Review configuration settings  
3. Check service logs: `docker-compose -f docker-compose-milvus.yml logs`
4. Create an issue with system details

### Quick Troubleshooting

**Services not starting?**
```bash
# Check Docker
docker --version
docker-compose --version

# Restart services
docker-compose -f docker-compose-milvus.yml down
docker-compose -f docker-compose-milvus.yml up -d
```

**API key issues?**
1. Ensure `.env` file exists (copy from `.env.example`)
2. Add your `GOOGLE_API_KEY` from [Google AI Studio](https://ai.google.dev/)
3. Restart the application

---

**Happy querying with Gemini Flash 2.0! ğŸ¤–ğŸ“šâœ¨**